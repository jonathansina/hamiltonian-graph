{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hamiltonian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graph4443.png</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graph1905.png</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graph7719.png</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>graph4902.png</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>graph4114.png</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4423</th>\n",
       "      <td>graph4672.png</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4424</th>\n",
       "      <td>graph3437.png</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>graph3649.png</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>graph893.png</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>graph7058.png</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4428 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name hamiltonian\n",
       "0     graph4443.png         yes\n",
       "1     graph1905.png          no\n",
       "2     graph7719.png          no\n",
       "3     graph4902.png          no\n",
       "4     graph4114.png         yes\n",
       "...             ...         ...\n",
       "4423  graph4672.png         yes\n",
       "4424  graph3437.png         yes\n",
       "4425  graph3649.png          no\n",
       "4426   graph893.png         yes\n",
       "4427  graph7058.png          no\n",
       "\n",
       "[4428 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(\"../data/train_info.csv\")\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    img = np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "    return img / 255\n",
    "\n",
    "def convert_to_array(data_dir, labels):\n",
    "    files = os.listdir(data_dir)\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    for picture in files:\n",
    "        img = cv2.imread(data_dir + f\"/{picture}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (400, 400))\n",
    "        img = rgb2gray(img)\n",
    "        \n",
    "        img = img.reshape(1, 400, 400)\n",
    "        \n",
    "        label = labels[labels[\"file_name\"] == f'{picture}'][\"hamiltonian\"].to_list()\n",
    "        \n",
    "        dataset_x.append(img)\n",
    "        dataset_y.append(label[0])\n",
    "    \n",
    "    return np.array(dataset_x), dataset_y\n",
    "\n",
    "data_train = convert_to_array(\"../data/train_images/train_images\", labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3542, 1, 400, 400), (886, 1, 400, 400))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape, images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_sample(images, label):\n",
    "    random_indices = np.random.choice(images.shape[0], 12, replace=False)\n",
    "    plt.figure(figsize=(20, 10), dpi=200)\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(images[idx], cmap='gray')\n",
    "        plt.title(f\"Hamiltonian = {label.iloc[idx]['hamiltonian']}\")\n",
    "        plt.axis('on')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.tight_layout()\n",
    "\n",
    "# plot_random_sample(images_train, labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(images, labels, num_augmentations):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        for _ in range(num_augmentations):\n",
    "            angle = np.random.uniform(-90, 90)\n",
    "            rotated_image = ndimage.rotate(images[i], angle, reshape=True)\n",
    "\n",
    "            shift = np.random.uniform(-5, 5, 2)\n",
    "            shifted_image = ndimage.shift(rotated_image, shift)\n",
    "\n",
    "            if np.random.rand() > 0.5:\n",
    "                flipped_image = np.fliplr(shifted_image)\n",
    "            else:\n",
    "                flipped_image = shifted_image\n",
    "\n",
    "            augmented_images.append(flipped_image)\n",
    "            augmented_labels.append(labels.iloc[i])\n",
    "\n",
    "    max_shape = np.max([img.shape for img in augmented_images], axis=0)\n",
    "\n",
    "    resized_images = []\n",
    "    for img in augmented_images:\n",
    "        resized_img = cv2.resize(img, (max_shape[1], max_shape[0]), interpolation=cv2.INTER_AREA)\n",
    "        resized_images.append(resized_img)\n",
    "\n",
    "    return np.array(resized_images), pd.DataFrame(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_data = augment_data(images, label[\"hamiltonian\"], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Moedel Design**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    \n",
    "device_name = \"cpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = [1.0 if i == \"yes\" else 0.0 for i in labels_train]\n",
    "labels_test = [1.0 if i == \"yes\" else 0.0 for i in labels_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3542, 1, 400, 400]),\n",
       " torch.Size([3542]),\n",
       " torch.Size([886, 1, 400, 400]),\n",
       " torch.Size([886]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_images_train = torch.from_numpy(images_train).type(torch.float).to(device)\n",
    "torch_labels_train = torch.from_numpy(np.array(labels_train)).type(torch.float).to(device)\n",
    "\n",
    "torch_images_test = torch.from_numpy(images_test).type(torch.float).to(device)\n",
    "torch_labels_test = torch.from_numpy(np.array(labels_test)).type(torch.float).to(device)\n",
    "\n",
    "torch_images_train.size(), torch_labels_train.size(), torch_images_test.size(), torch_labels_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(torch_images_train, torch_labels_train)\n",
    "dataset_test = TensorDataset(torch_images_test, torch_labels_test)\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, \n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test, \n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(dataloader_train):\n",
    "    if i == 0:\n",
    "        res = sample[0]\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 400, 400])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=64,\n",
    "            kernel_size=6,\n",
    "            stride=1,\n",
    "            padding=\"same\"\n",
    "        ) \n",
    "        self.batch_norm_1 = nn.BatchNorm2d(\n",
    "            num_features=64\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=64, \n",
    "            out_channels=128,\n",
    "            kernel_size=16, \n",
    "            stride=1,\n",
    "            padding=\"same\"\n",
    "        )\n",
    "        self.batch_norm_2 = nn.BatchNorm2d(\n",
    "            num_features=128\n",
    "        )\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout2d(p=0.25)\n",
    "        self.dropout_2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=12800, \n",
    "            out_features=128\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=128, \n",
    "            out_features=1\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.dropout_1(x)\n",
    "        \n",
    "        print(x.size())\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout_1(x)\n",
    "        \n",
    "        print(x.size())\n",
    "        \n",
    "        x = x.view(-1, 12800)\n",
    "        print(x.size())\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        output = F.sigmoid(x)\n",
    "        # x = self.dropout_2(x)\n",
    "        \n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(6, 6), stride=(1, 1), padding=same)\n",
       "  (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(16, 16), stride=(1, 1), padding=same)\n",
       "  (batch_norm_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout_1): Dropout2d(p=0.25, inplace=False)\n",
       "  (dropout_2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=12800, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(dataloader_train):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(dataloader_train) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "torch.Size([32, 1, 400, 400])\n",
      "torch.Size([32, 64, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(dataloader_test):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
